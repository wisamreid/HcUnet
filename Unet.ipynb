{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLMmj1M3Qo9F"
   },
   "outputs": [],
   "source": [
    "from unet import unet_constructor as GUnet\n",
    "import dataloader as dataloader\n",
    "from loss import dice_loss, cross_entropy_loss, random_cross_entropy\n",
    "import transforms as t\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import skimage.io as io\n",
    "import os\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nbvse8ATuXoQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = dataloader.stack(path='./Data/train',\n",
    "                        joint_transforms=[t.to_float(),\n",
    "                                          t.reshape(),\n",
    "                                          t.nul_crop(rate=.85),\n",
    "                                          t.random_crop([128, 128, 24]),\n",
    "                                          t.random_rotate(),\n",
    "                                          #t.random_affine()\n",
    "                                          ],\n",
    "                        image_transforms=[\n",
    "                                          t.drop_channel(.8), \n",
    "                                          t.random_gamma((.7, 1.3)),\n",
    "                                          t.random_intensity(),\n",
    "                                          t.spekle(0.00001),\n",
    "                                          t.clean_image(),\n",
    "                                          t.normalize([0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5])\n",
    "                                          ]\n",
    "                        )\n",
    "\n",
    "val_data = dataloader.stack(path='./Data/train',\n",
    "                        joint_transforms=[t.to_float(),\n",
    "                                          t.reshape(),\n",
    "                                          t.random_crop([512, 512, 30]),\n",
    "                                          t.random_rotate(90),\n",
    "                                          #t.random_affine\n",
    "                                          ],\n",
    "                        image_transforms=[\n",
    "                                          #t.random_gamma((.8,1.2)),\n",
    "                                          #t.spekle(),\n",
    "                                          t.normalize([0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5])\n",
    "                                          ]\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ge1kgUHcQyye"
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "# Try with much smaller image\n",
    "\n",
    "test = GUnet(image_dimensions=3,\n",
    "             in_channels=4,\n",
    "             out_channels=1,\n",
    "             #feature_sizes=[16,32,64,128],\n",
    "             feature_sizes=[32, 64, 128],\n",
    "             kernel={'conv1': (7, 7, 3), 'conv2': (7, 7, 1)}, # Try with 9 because its symetric\n",
    "             upsample_kernel=(7, 7, 2),\n",
    "             max_pool_kernel=(2, 2, 1),\n",
    "             upsample_stride=(2, 2, 1),\n",
    "             dilation=1, # Try dialated \n",
    "             groups=2).to(device)\n",
    "\n",
    "\n",
    "test = test.type(torch.float)\n",
    "\n",
    "# image, mask, pwl = data[0]\n",
    "\n",
    "# out = test.forward(image.float().to(device))\n",
    "# out_loss = dice_loss(out, mask.to(device))#, pwl.float().to('cuda'))\n",
    "\n",
    "sd = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcUBS1bHppYS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test.load('May14_chris-MS-7C37_2.unet') # <- BEST YET\n",
    "\n",
    "sd = 'Jul13_chris-MS-7C37_1.unet'\n",
    "test.load(sd)\n",
    "test.cuda()\n",
    "test.train()\n",
    "print('Yeet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "gamma = .75\n",
    "weight_cel = 1.3\n",
    "weight_cel_random = 0\n",
    "weight_dice = 1\n",
    "num_pixels_cel_random = 20000\n",
    "cel_z_weighting_method = None\n",
    "momentum = .99\n",
    "nesterov=True\n",
    "timestart = time.asctime()\n",
    "\n",
    "device = 'cuda:0'                 \n",
    "\n",
    "epoch_loss = []\n",
    "running_loss = []\n",
    "epoch = 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment=timestart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvqbnGucp2s0"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(test.parameters(), lr = lr)\n",
    "#optimizer = torch.optim.SGD(test.parameters(), lr=lr, momentum=momentum, nesterov=nesterov)\n",
    "\n",
    "scheduler_1 = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=gamma)\n",
    "scheduler_2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "zbF3sMdZRKb5",
    "outputId": "6832ad5d-92bf-4554-aa0f-387fd63508f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:  # loop over the dataset multiple times\n",
    "    epoch_loss_dice=[]\n",
    "    epoch_loss_BCE=[]\n",
    "    epoch_loss_joint=[]\n",
    "    for i in range(len(data)):\n",
    "        image, mask, pwl  = data[i]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = test(image.float().to('cuda'))\n",
    "\n",
    "\n",
    "        #out_loss = ((np.cos(2*np.pi * (epoch/100))+1)/4 + .2) * cross_entropy_loss(out, mask.to('cuda'), pwl.to('cuda'), 5) +\\\n",
    "        #           dice_loss(out, mask.to('cuda'))\n",
    "        #out_loss = weight_cel * cross_entropy_loss(out, mask.to('cuda'), pwl.to('cuda'), weight=cel_z_weighting_method) +\\\n",
    "        #           weight_dice * dice_loss(out, mask.to('cuda'))\n",
    "        \n",
    "        out_loss = weight_cel_random * random_cross_entropy(out, mask.to('cuda'), pwl.to('cuda'), num_pixels_cel_random) +\\\n",
    "                   weight_cel * cross_entropy_loss(out, mask.to('cuda'), pwl.to('cuda'), weight=cel_z_weighting_method) +\\\n",
    "                   weight_dice * dice_loss(out, mask.to('cuda'))\n",
    "        \n",
    "        \n",
    "        if torch.isnan(out_loss):\n",
    "            print(cross_entropy_loss(out, mask.to('cuda'), pwl.to('cuda')))\n",
    "            print(dice_loss(out, mask.to('cuda')))\n",
    "            print(torch.isnan(mask.float()).any(), torch.isnan(image.float().any()), torch.isnan(pwl.float()).any())\n",
    "            print(out.shape)\n",
    "            raise ValueError\n",
    "        \n",
    "        del out\n",
    "        \n",
    "        epoch_loss_joint.append(out_loss.item())\n",
    "        \n",
    "        print(f'\\r\\033[32mEpoch: \\033[0m{epoch} |',end='')\n",
    "        print(f' JOINT |', end='')\n",
    "        print(f' {i} |',end='')\n",
    "        print(f' \\033[35mPOL: \\033[0m{str(running_loss)[0:8]} -->', end='')\n",
    "        print(f' \\033[35mOL: \\033[0m{str(out_loss.item())[0:8]}', end='')\n",
    "\n",
    "        out_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        running_loss = out_loss.item()\n",
    "        \n",
    "        del out_loss, mask, pwl \n",
    "        \n",
    "    to_tb = np.array(epoch_loss_joint).sum()/len(epoch_loss_joint)\n",
    "    writer.add_scalar('Cyclic Joint Loss Train', to_tb, epoch)\n",
    "    epoch_loss.append(to_tb)\n",
    "    epoch += 1\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "savename = 'Jul13_chris-MS-7C37_2.unet'\n",
    "\n",
    "if os.path.exists(savename):\n",
    "    raise NameError('Save file of this path already exists.')\n",
    "\n",
    "hyperparameters =  {'lr': lr,\n",
    "                    'epoch_final': epoch,\n",
    "                    'weight_cross_entropy_loss':weight_cel,\n",
    "                    'weight_dice_loss':weight_dice,\n",
    "                    'weight_cel_random':weight_cel_random, \n",
    "                    'cel_random_num_pixels': num_pixels_cel_random,\n",
    "                    'epoch_loss': epoch_loss,\n",
    "                    'cross_entropy_loss_z_weighting_method': cel_z_weighting_method,\n",
    "                    'transfer_learning_unet_starting_state_dict_name': sd,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'time_started': timestart,\n",
    "                    'time_finished': time.asctime(),\n",
    "                    'savename': savename\n",
    "                   }\n",
    "\n",
    "test.save(savename, hyperparameters)\n",
    "print(f'Saved as {savename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image, mask, pwl  = val_data[1]\n",
    "#test.eval()\n",
    "#test.cpu()\n",
    "with torch.no_grad(): \n",
    "    out = test(image.float().cuda())\n",
    "\n",
    "pred = F.sigmoid(out) > .5\n",
    "for i in range(image.shape[-1]):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    #plt.imshow(image[0,[0,2,1],:,:,i].float().transpose(0,1).transpose(1,2)*.5 + .5)\n",
    "    #plt.imshow(image[0,0:3,:,:,i].float().transpose(0,1).transpose(1,2)*.5 + .5)\n",
    "    plt.imshow(mask[0,0,:,:,i].float(), cmap = 'Greens')\n",
    "    plt.imshow(pred[0,0,:,:,i].cpu().detach().numpy(), cmap=plt.cm.nipy_spectral,alpha=.3)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}